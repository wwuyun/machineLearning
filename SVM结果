实验一结果：
              precision    recall  f1-score   support

           0       0.68      0.75      0.71      2076
           1       0.91      0.93      0.92      2108
           2       0.68      0.62      0.65      2094
           3       0.63      0.64      0.63      2148
           4       0.61      0.66      0.64      2070
           5       0.90      0.86      0.88      2144
           6       0.54      0.45      0.49      2131
           7       0.86      0.91      0.88      2076
           8       0.88      0.92      0.90      2017
           9       0.93      0.92      0.92      2136

    accuracy                           0.76     21000
   macro avg       0.76      0.77      0.76     21000
weighted avg       0.76      0.76      0.76     21000

Accuracy: 0.7644285714285715


实验二结果：
Using SVM with linear kernel:
              precision    recall  f1-score   support

           0       0.68      0.75      0.71      2076
           1       0.91      0.93      0.92      2108
           2       0.68      0.62      0.65      2094
           3       0.63      0.64      0.63      2148
           4       0.61      0.66      0.64      2070
           5       0.90      0.86      0.88      2144
           6       0.54      0.45      0.49      2131
           7       0.86      0.91      0.88      2076
           8       0.88      0.92      0.90      2017
           9       0.93      0.92      0.92      2136

    accuracy                           0.76     21000
   macro avg       0.76      0.77      0.76     21000
weighted avg       0.76      0.76      0.76     21000

Using SVM with poly kernel:
              precision    recall  f1-score   support

           0       0.72      0.77      0.74      2076
           1       0.93      0.94      0.93      2108
           2       0.71      0.67      0.69      2094
           3       0.69      0.68      0.68      2148
           4       0.64      0.70      0.67      2070
           5       0.93      0.91      0.92      2144
           6       0.60      0.51      0.55      2131
           7       0.89      0.92      0.91      2076
           8       0.92      0.94      0.93      2017
           9       0.95      0.93      0.94      2136

    accuracy                           0.80     21000
   macro avg       0.80      0.80      0.80     21000
weighted avg       0.80      0.80      0.80     21000

Using SVM with rbf kernel:
              precision    recall  f1-score   support

           0       0.71      0.77      0.74      2076
           1       0.92      0.94      0.93      2108
           2       0.71      0.66      0.68      2094
           3       0.67      0.67      0.67      2148
           4       0.64      0.69      0.66      2070
           5       0.92      0.90      0.91      2144
           6       0.59      0.50      0.54      2131
           7       0.88      0.92      0.90      2076
           8       0.91      0.94      0.92      2017
           9       0.94      0.92      0.93      2136

    accuracy                           0.79     21000
   macro avg       0.79      0.79      0.79     21000
weighted avg       0.79      0.79      0.79     21000



实验一结果：
